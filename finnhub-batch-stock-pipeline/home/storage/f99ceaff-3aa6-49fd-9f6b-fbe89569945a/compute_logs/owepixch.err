[32m2024-05-23 20:33:25 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - f99ceaff-3aa6-49fd-9f6b-fbe89569945a - 181087 - LOGS_CAPTURED - Started capturing logs in process (pid: 181087).
[32m2024-05-23 20:33:25 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - f99ceaff-3aa6-49fd-9f6b-fbe89569945a - 181087 - fact_wrh_tables - STEP_START - Started execution of step "fact_wrh_tables".
[32m2024-05-23 20:33:26 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - f99ceaff-3aa6-49fd-9f6b-fbe89569945a - fact_wrh_tables - Loading S3 object from: s3a://dagster-api/staging/2024-05-23/metric
[32m2024-05-23 20:33:31 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - f99ceaff-3aa6-49fd-9f6b-fbe89569945a - 181087 - fact_wrh_tables - LOADED_INPUT - Loaded input "metric" using input manager "s3_prqt_io_manager"
[32m2024-05-23 20:33:31 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - f99ceaff-3aa6-49fd-9f6b-fbe89569945a - fact_wrh_tables - Loading S3 object from: s3a://dagster-api/staging/2024-05-23/series
[32m2024-05-23 20:33:32 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - f99ceaff-3aa6-49fd-9f6b-fbe89569945a - 181087 - fact_wrh_tables - LOADED_INPUT - Loaded input "series" using input manager "s3_prqt_io_manager"
[32m2024-05-23 20:33:32 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - f99ceaff-3aa6-49fd-9f6b-fbe89569945a - 181087 - fact_wrh_tables - STEP_INPUT - Got input "metric" of type "Any". (Type check passed).
[32m2024-05-23 20:33:32 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - f99ceaff-3aa6-49fd-9f6b-fbe89569945a - 181087 - fact_wrh_tables - STEP_INPUT - Got input "series" of type "Any". (Type check passed).
[32m2024-05-23 20:33:43 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - f99ceaff-3aa6-49fd-9f6b-fbe89569945a - 181087 - fact_wrh_tables - STEP_OUTPUT - Yielded output "metric_fact_wrh" of type "Table". (Type check passed).
[32m2024-05-23 20:33:43 +0000[0m - dagster - [34mERROR[0m - [31m__ASSET_JOB - f99ceaff-3aa6-49fd-9f6b-fbe89569945a - 181087 - fact_wrh_tables - STEP_FAILURE - Execution of step "fact_wrh_tables" failed.

dagster._core.errors.DagsterExecutionHandleOutputError: Error occurred while handling output "metric_fact_wrh" of step "fact_wrh_tables"::

dagster._check.CheckError: DuckDBIOManager does not have a handler for type '<class 'pyarrow.lib.Table'>'. Has handlers for types '<class 'pyspark.sql.dataframe.DataFrame'>'. Please build the DuckDBIOManager with an type handler for type '<class 'pyarrow.lib.Table'>', so the DuckDBIOManager can correctly handle the output.

Stack Trace:
  File "/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/dagster/_core/execution/plan/utils.py", line 54, in op_execution_error_boundary
    yield
  File "/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/dagster/_utils/__init__.py", line 468, in iterate_with_context
    next_output = next(iterator)
                  ^^^^^^^^^^^^^^
  File "/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/dagster/_core/execution/plan/execute_step.py", line 800, in _gen_fn
    gen_output = output_manager.handle_output(output_context, output.value)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/dagster/_core/storage/db_io_manager.py", line 139, in handle_output
    self._check_supported_type(obj_type)
  File "/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/dagster/_core/storage/db_io_manager.py", line 285, in _check_supported_type
    raise CheckError(msg)
[0m
