[32m2024-05-25 16:10:59 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - 3b4e1804-6cce-49a9-881c-6f7230bf729d - 132080 - LOGS_CAPTURED - Started capturing logs in process (pid: 132080).
[32m2024-05-25 16:10:59 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - 3b4e1804-6cce-49a9-881c-6f7230bf729d - 132080 - fact_tables - STEP_START - Started execution of step "fact_tables".
[32m2024-05-25 16:10:59 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - 3b4e1804-6cce-49a9-881c-6f7230bf729d - fact_tables - Loading S3 object from: s3a://dagster-api/staging/2024-05-25/metric
[32m2024-05-25 16:11:06 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - 3b4e1804-6cce-49a9-881c-6f7230bf729d - 132080 - fact_tables - LOADED_INPUT - Loaded input "metric" using input manager "s3_prqt_io_manager"
[32m2024-05-25 16:11:06 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - 3b4e1804-6cce-49a9-881c-6f7230bf729d - fact_tables - Loading S3 object from: s3a://dagster-api/staging/2024-05-25/series
[32m2024-05-25 16:11:07 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - 3b4e1804-6cce-49a9-881c-6f7230bf729d - 132080 - fact_tables - LOADED_INPUT - Loaded input "series" using input manager "s3_prqt_io_manager"
[32m2024-05-25 16:11:07 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - 3b4e1804-6cce-49a9-881c-6f7230bf729d - 132080 - fact_tables - STEP_INPUT - Got input "metric" of type "Any". (Type check passed).
[32m2024-05-25 16:11:07 +0000[0m - dagster - [34mDEBUG[0m - __ASSET_JOB - 3b4e1804-6cce-49a9-881c-6f7230bf729d - 132080 - fact_tables - STEP_INPUT - Got input "series" of type "Any". (Type check passed).
[32m2024-05-25 16:11:20 +0000[0m - dagster - [34mERROR[0m - [31m__ASSET_JOB - 3b4e1804-6cce-49a9-881c-6f7230bf729d - 132080 - fact_tables - STEP_FAILURE - Execution of step "fact_tables" failed.

dagster._core.errors.DagsterExecutionStepExecutionError: Error occurred while executing op "fact_tables"::

TypeError: Cannot convert Column to pyarrow.lib.RecordBatch

Stack Trace:
  File "/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/dagster/_core/execution/plan/utils.py", line 54, in op_execution_error_boundary
    yield
  File "/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/dagster/_utils/__init__.py", line 468, in iterate_with_context
    next_output = next(iterator)
                  ^^^^^^^^^^^^^^
  File "/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/dagster/_core/execution/plan/compute_generator.py", line 141, in _coerce_op_compute_fn_to_iterator
    result = invoke_compute_fn(
             ^^^^^^^^^^^^^^^^^^
  File "/workspace/.pyenv_mirror/user/current/lib/python3.12/site-packages/dagster/_core/execution/plan/compute_generator.py", line 129, in invoke_compute_fn
    return fn(context, **args_to_pass) if context_arg_provided else fn(**args_to_pass)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspace/practical-data-engineering/finnhub-batch-stock-pipeline/finnhub_batch_stock_pipeline/assets/fact_tables.py", line 63, in fact_tables
    series_fact_lake = pa.Table.from_batches(series_fact)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "pyarrow/table.pxi", line 4755, in pyarrow.lib.Table.from_batches
[0m
